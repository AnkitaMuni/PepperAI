{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ukCoLemmZt31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-07T07:37:05.601229Z",
     "iopub.status.busy": "2026-02-07T07:37:05.600523Z",
     "iopub.status.idle": "2026-02-07T07:37:41.602202Z",
     "shell.execute_reply": "2026-02-07T07:37:41.601388Z",
     "shell.execute_reply.started": "2026-02-07T07:37:05.601201Z"
    },
    "executionInfo": {
     "elapsed": 21721,
     "status": "ok",
     "timestamp": 1770392909255,
     "user": {
      "displayName": "Ankita Muni",
      "userId": "11920035534731355889"
     },
     "user_tz": -330
    },
    "id": "ukCoLemmZt31",
    "outputId": "5200fca9-5872-40bd-d0a8-29acc1e8381f",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.3)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2026.1.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1yZBuHL9CBjOZjfen8FSas7ouPVQz-yYj\n",
      "From (redirected): https://drive.google.com/uc?id=1yZBuHL9CBjOZjfen8FSas7ouPVQz-yYj&confirm=t&uuid=fe720751-5b3e-46f3-b86a-516916905e7c\n",
      "To: /kaggle/working/augmented_pepper_dataset.zip\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.00G/4.00G [00:29<00:00, 135MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'augmented_pepper_dataset.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install gdown\n",
    "import gdown\n",
    "# Replace 'FILE_ID' with the actual ID from your Drive share link\n",
    "file_id = '1yZBuHL9CBjOZjfen8FSas7ouPVQz-yYj' \n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', 'augmented_pepper_dataset.zip', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "YIcWa4UkZwOb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-07T07:38:05.201194Z",
     "iopub.status.busy": "2026-02-07T07:38:05.200734Z",
     "iopub.status.idle": "2026-02-07T07:38:34.179827Z",
     "shell.execute_reply": "2026-02-07T07:38:34.179108Z",
     "shell.execute_reply.started": "2026-02-07T07:38:05.201161Z"
    },
    "executionInfo": {
     "elapsed": 91128,
     "status": "ok",
     "timestamp": 1770393043859,
     "user": {
      "displayName": "Ankita Muni",
      "userId": "11920035534731355889"
     },
     "user_tz": -330
    },
    "id": "YIcWa4UkZwOb",
    "outputId": "5bf68f99-95a4-48eb-fc9d-9a7be4888232",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting augmented dataset...\n",
      "âœ… Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "zip_path = 'augmented_pepper_dataset.zip'\n",
    "extract_to = '/kaggle/working/training_data'\n",
    "\n",
    "# 1. Force a clean start by removing the old folder if it exists\n",
    "if os.path.exists(extract_to):\n",
    "    shutil.rmtree(extract_to)\n",
    "    print(f\"ðŸ—‘ï¸ Cleaned up existing folder: {extract_to}\")\n",
    "\n",
    "# 2. Extract the data\n",
    "print(\"Extracting augmented dataset...\")\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "print(\"âœ… Extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66514024-5621-439a-8cc4-cffc1d4f2134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T07:38:39.481236Z",
     "iopub.status.busy": "2026-02-07T07:38:39.480931Z",
     "iopub.status.idle": "2026-02-07T07:38:39.587501Z",
     "shell.execute_reply": "2026-02-07T07:38:39.586713Z",
     "shell.execute_reply.started": "2026-02-07T07:38:39.481210Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      ".virtual_documents/\n",
      "training_data/\n",
      "    content/\n",
      "        dataset/\n",
      "            HEALTHY/\n",
      "                black pepper RAW/\n",
      "                black_pepper_healthy/\n",
      "                augmented/\n",
      "                Black pepper detection1.v1i.yolov8/\n",
      "                    test/\n",
      "                        images/\n",
      "                        labels/\n",
      "                    train/\n",
      "                        images/\n",
      "                        labels/\n",
      "                    valid/\n",
      "                        images/\n",
      "                        labels/\n",
      "                MERGED/\n",
      "            UNHEALTHY/\n",
      "                Pollu_Disease/\n",
      "                black_pepper_yellow_mottle_virus/\n",
      "                black_pepper_leaf_blight/\n",
      "                Slow-Decline/\n",
      "                augmented/\n",
      "                Footrot/\n",
      "                MERGED/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# This will list everything in your working directory\n",
    "for root, dirs, files in os.walk('/kaggle/working/'):\n",
    "    level = root.replace('/kaggle/working/', '').count(os.sep)\n",
    "    indent = ' ' * 4 * (level)\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "AUmGzZsIZ8kK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "execution": {
     "iopub.execute_input": "2026-02-07T07:38:44.101001Z",
     "iopub.status.busy": "2026-02-07T07:38:44.100704Z",
     "iopub.status.idle": "2026-02-07T08:26:30.920443Z",
     "shell.execute_reply": "2026-02-07T08:26:30.919675Z",
     "shell.execute_reply.started": "2026-02-07T07:38:44.100976Z"
    },
    "executionInfo": {
     "elapsed": 439506,
     "status": "error",
     "timestamp": 1770393731695,
     "user": {
      "displayName": "Ankita Muni",
      "userId": "11920035534731355889"
     },
     "user_tz": -330
    },
    "id": "AUmGzZsIZ8kK",
    "outputId": "8d5f58b5-1ea0-41e8-a53c-ff2d83ff097d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected classes: ['HEALTHY', 'UNHEALTHY']\n",
      "Total augmented images found: 47952\n",
      "Training on: cuda\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 183MB/s]\n",
      "/tmp/ipykernel_55/373380478.py:79: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/2398 [00:00<?, ?it/s]/tmp/ipykernel_55/373380478.py:95: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:46<00:00,  8.36it/s, loss=0.021]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9910\n",
      "Saved checkpoint: pepper_resnet18_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:45<00:00,  8.41it/s, loss=3.82e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9963\n",
      "Saved checkpoint: pepper_resnet18_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:44<00:00,  8.41it/s, loss=0.00118] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9984\n",
      "Saved checkpoint: pepper_resnet18_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:45<00:00,  8.41it/s, loss=0.0104]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9981\n",
      "Saved checkpoint: pepper_resnet18_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:45<00:00,  8.41it/s, loss=7.88e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9984\n",
      "Saved checkpoint: pepper_resnet18_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:45<00:00,  8.41it/s, loss=1.28e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9985\n",
      "Saved checkpoint: pepper_resnet18_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:45<00:00,  8.41it/s, loss=0.000236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9987\n",
      "Saved checkpoint: pepper_resnet18_epoch_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:44<00:00,  8.42it/s, loss=0.00102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9990\n",
      "Saved checkpoint: pepper_resnet18_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:44<00:00,  8.42it/s, loss=3.14e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9993\n",
      "Saved checkpoint: pepper_resnet18_epoch_9.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2398/2398 [04:44<00:00,  8.43it/s, loss=1.19e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9993\n",
      "Saved checkpoint: pepper_resnet18_epoch_10.pth\n",
      "âœ… Model weights saved! Download it from the 'Output' pane.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Subset, Dataset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "# Added for speed and memory efficiency\n",
    "from torch.cuda.amp import GradScaler, autocast \n",
    "\n",
    "# 1. Path Configuration\n",
    "healthy_aug_dir = '/kaggle/working/training_data/content/dataset/HEALTHY/augmented'\n",
    "unhealthy_aug_dir = '/kaggle/working/training_data/content/dataset/UNHEALTHY/augmented'\n",
    "\n",
    "# 2. Data Transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((500, 500)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 3. Custom Loader\n",
    "class AugmentedPepperDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, label=0):\n",
    "        self.image_paths = glob.glob(os.path.join(root_dir, '*.*'))\n",
    "        self.transform = transform\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label\n",
    "\n",
    "dataset_healthy = AugmentedPepperDataset(healthy_aug_dir, transform=data_transforms, label=0)\n",
    "dataset_unhealthy = AugmentedPepperDataset(unhealthy_aug_dir, transform=data_transforms, label=1)\n",
    "full_dataset = ConcatDataset([dataset_healthy, dataset_unhealthy])\n",
    "\n",
    "print(f\"Detected classes: ['HEALTHY', 'UNHEALTHY']\")\n",
    "print(f\"Total augmented images found: {len(full_dataset)}\")\n",
    "\n",
    "# 4. Train/Test Split\n",
    "indices = list(range(len(full_dataset)))\n",
    "targets = [0] * len(dataset_healthy) + [1] * len(dataset_unhealthy)\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices,\n",
    "    train_size=0.8,\n",
    "    random_state=42,\n",
    "    stratify=targets\n",
    ")\n",
    "\n",
    "train_data = Subset(full_dataset, train_idx)\n",
    "test_data = Subset(full_dataset, test_idx)\n",
    "\n",
    "# SPEED BOOST: Added num_workers and pin_memory\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 5. Initialize ResNet18\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# STABILITY: Initialize Scaler for Mixed Precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 6. Training Loop\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # SPEED BOOST: Use autocast for FP16 training\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # STABILITY: Scaled backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        epoch_acc = running_corrects.double() / len(train_data)\n",
    "        print(f\"Training Accuracy: {epoch_acc:.4f}\")\n",
    "        \n",
    "        # RESUME SUPPORT: Save a checkpoint after every epoch\n",
    "        checkpoint_name = f'pepper_resnet18_epoch_{epoch+1}.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'acc': epoch_acc\n",
    "        }, checkpoint_name)\n",
    "        print(f\"Saved checkpoint: {checkpoint_name}\")\n",
    "        \n",
    "        torch.cuda.empty_cache() \n",
    "\n",
    "    return model\n",
    "\n",
    "# Start training\n",
    "model = train_model(model, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "# 7. Save Final Model\n",
    "torch.save(model.state_dict(), 'pepper_resnet18_augmented_500px.pth')\n",
    "print(\"âœ… Model weights saved! Download it from the 'Output' pane.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
